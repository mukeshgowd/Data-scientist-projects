{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Customer Transaction Prediction\n", "\n", "This notebook addresses the PRCP-1003 capstone project:\n", "- Perform predictive modeling to identify which customers will make a transaction.\n", "- Evaluate multiple models and select the best one.\n", "- Discuss challenges and methods used to overcome them.\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Import libraries\n", "import pandas as pd\n", "import numpy as np\n", "import matplotlib.pyplot as plt\n", "import seaborn as sns\n", "from sklearn.model_selection import train_test_split, cross_val_score\n", "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score\n", "from sklearn.linear_model import LogisticRegression\n", "from sklearn.ensemble import RandomForestClassifier\n", "from xgboost import XGBClassifier\n", "from lightgbm import LGBMClassifier\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Load data\n", "df = pd.read_csv(\"train.csv\")\n", "df.head()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Basic checks\n", "print(df.shape)\n", "print(df.isnull().sum().sum())\n", "df['target'].value_counts(normalize=True)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Split features and target\n", "X = df.drop(['ID_code', 'target'], axis=1)\n", "y = df['target']\n", "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Train and evaluate models\n", "models = {\n", "    'Logistic Regression': LogisticRegression(max_iter=1000),\n", "    'Random Forest': RandomForestClassifier(n_estimators=100),\n", "    'XGBoost': XGBClassifier(use_label_encoder=False, eval_metric='logloss'),\n", "    'LightGBM': LGBMClassifier()\n", "}\n", "\n", "for name, model in models.items():\n", "    model.fit(X_train, y_train)\n", "    y_pred = model.predict(X_test)\n", "    acc = accuracy_score(y_test, y_pred)\n", "    roc = roc_auc_score(y_test, model.predict_proba(X_test)[:, 1])\n", "    print(f\"{name} - Accuracy: {acc:.4f}, ROC-AUC: {roc:.4f}\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Final Model Selection\n", "Based on evaluation metrics, the model with the best ROC-AUC score will be selected for production use."]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Challenges Faced\n", "- Feature names are anonymized: made EDA less informative.\n", "- Imbalanced dataset: handled by using stratified sampling and ROC-AUC as evaluation metric.\n", "- Model tuning was constrained due to lack of feature meaning.\n"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"name": "python", "version": "3.8"}}, "nbformat": 4, "nbformat_minor": 4}